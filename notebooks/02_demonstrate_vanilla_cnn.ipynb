{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Demonstrate Vanilla CNN\n",
    "\n",
    "**Summary**\n",
    "\n",
    "- 95.99 % Average F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data as pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the annotations file that contains the label and the image file name\n",
    "labels = pd.read_csv('../data/raw/annotations.csv', header=None, names=['fname','label'])\n",
    "\n",
    "# Shuffle data\n",
    "labels = labels.sample(frac=1).reset_index()\n",
    "\n",
    "# Use a list comprehension to loop over image file names and import one by one and store pixel values\n",
    "x = np.array([image.img_to_array(image.load_img('../data/raw/all/'+fname.lower(), target_size=(128, 128))) for fname in labels['fname']])\n",
    "\n",
    "# Because the names are strings, the neural network only takes in numerical formats so we will one-hot encode the label\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels['label'])\n",
    "y = integer_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define an architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (5, 5), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Feed to a densily connected layer for prediction\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizers.Adam(lr=0.001),\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiment for 10 Stratified K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kfold iteration 1/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        20\n",
      "           1       0.95      0.95      0.95        20\n",
      "\n",
      "    accuracy                           0.95        40\n",
      "   macro avg       0.95      0.95      0.95        40\n",
      "weighted avg       0.95      0.95      0.95        40\n",
      "\n",
      "Kfold iteration 2/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "Kfold iteration 3/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93        20\n",
      "           1       0.95      0.90      0.92        20\n",
      "\n",
      "    accuracy                           0.93        40\n",
      "   macro avg       0.93      0.93      0.92        40\n",
      "weighted avg       0.93      0.93      0.92        40\n",
      "\n",
      "Kfold iteration 4/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        20\n",
      "           1       1.00      0.90      0.95        20\n",
      "\n",
      "    accuracy                           0.95        40\n",
      "   macro avg       0.95      0.95      0.95        40\n",
      "weighted avg       0.95      0.95      0.95        40\n",
      "\n",
      "Kfold iteration 5/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "Kfold iteration 6/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        20\n",
      "           1       0.95      1.00      0.98        20\n",
      "\n",
      "    accuracy                           0.97        40\n",
      "   macro avg       0.98      0.97      0.97        40\n",
      "weighted avg       0.98      0.97      0.97        40\n",
      "\n",
      "Kfold iteration 7/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        20\n",
      "           1       1.00      0.95      0.97        20\n",
      "\n",
      "    accuracy                           0.97        40\n",
      "   macro avg       0.98      0.97      0.97        40\n",
      "weighted avg       0.98      0.97      0.97        40\n",
      "\n",
      "Kfold iteration 8/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        20\n",
      "           1       1.00      0.90      0.95        20\n",
      "\n",
      "    accuracy                           0.95        40\n",
      "   macro avg       0.95      0.95      0.95        40\n",
      "weighted avg       0.95      0.95      0.95        40\n",
      "\n",
      "Kfold iteration 9/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        20\n",
      "           1       0.91      1.00      0.95        20\n",
      "\n",
      "    accuracy                           0.95        40\n",
      "   macro avg       0.95      0.95      0.95        40\n",
      "weighted avg       0.95      0.95      0.95        40\n",
      "\n",
      "Kfold iteration 10/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92        20\n",
      "           1       0.90      0.95      0.93        20\n",
      "\n",
      "    accuracy                           0.93        40\n",
      "   macro avg       0.93      0.93      0.92        40\n",
      "weighted avg       0.93      0.93      0.92        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All classification reports will be added here. When we are done we can average the f1 scores\n",
    "reports = []\n",
    "\n",
    "# Apply stratified K-fold ith 10 splits. Stratified means the same distribution of classes than the whole dataset\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Just for printing purposes\n",
    "id = 1\n",
    "\n",
    "for train_index, test_index in kf.split(x,y):\n",
    "    print('Kfold iteration {}/10'.format(id))\n",
    "    print('Total images: {} ---- Train images: {} ---- Test images: {}'.format(len(x),len(train_index),len(test_index)))\n",
    "\n",
    "    id += 1 \n",
    "    \n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "    model = build_model()\n",
    "    \n",
    "    datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                 rotation_range=10, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                                 width_shift_range=0.1, # randomly shift images horizontally (fraction of total width)\n",
    "                                 height_shift_range=0.1, \n",
    "                                 shear_range=0.1,\n",
    "                                 zoom_range=0.1)   \n",
    "    \n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # Adjust the learning rate over time. (Like we saw in class!)    \n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "    \n",
    "    history = model.fit_generator(datagen.flow(X_train, y_train, batch_size = 20), epochs = 20, \n",
    "                              validation_data = (X_test,y_test), steps_per_epoch=len(X_train) / 20,\n",
    "                              callbacks=[es, learning_rate_reduction], verbose=0)\n",
    "\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [np.round(p[0]) for p in y_pred]\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    reports.append(classification_report(y_test, y_pred,output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1-Score is: 95.99%\n"
     ]
    }
   ],
   "source": [
    "# We loop over all reports (1 per fold) and then compute the average of all weighted f1 scores\n",
    "final_f1_score = np.mean([rep['weighted avg']['f1-score'] for rep in reports])\n",
    "\n",
    "print('Final F1-Score is: {}%'.format(np.round(final_f1_score*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:smile] *",
   "language": "python",
   "name": "conda-env-smile-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
