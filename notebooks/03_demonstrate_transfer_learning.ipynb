{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Demonstrate Transfer Learning\n",
    "\n",
    "**Summary**\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.applications import VGG16\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the convolutional base from imagenet\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'images/training'\n",
    "validation_dir = 'images/testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)  # Rescale images to 0-1\n",
    "batch_size = 32  # Number of batches to read from default 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(directory, sample_count):\n",
    "    \"\"\"\n",
    "    extract the features when processing images through the convolutional base. The features will be fed to \n",
    "    classification neural network\n",
    "    \"\"\"\n",
    "    # Create emtpy array\n",
    "    features = np.zeros(shape=(sample_count, 2, 2, 512))\n",
    "    # Here I added the shape \n",
    "    labels = np.zeros(shape=(sample_count,2))\n",
    "    # define the generator that is going to grab 20 images at a time and loop infinitly.\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(64,64),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "        )\n",
    "    # Usefull for mapping label names\n",
    "    label_map = (generator.class_indices)\n",
    "    i=0\n",
    "    \n",
    "    # Extract features\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        # Break because the generator will loop infinitly\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels, label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_training = 0\n",
    "for folder in os.listdir(\"images/testing\"):\n",
    "    total_training += len(os.listdir( os.path.join('images/testing',folder)))\n",
    "    print(len(os.listdir( os.path.join('images/testing',folder))))\n",
    "print(total_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels, label_map = extract_features(train_dir, 1000)\n",
    "validation_features, validation_labels, label_map = extract_features(validation_dir, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_features = np.reshape(train_features, (1000, 2 * 2 * 512))\n",
    "validation_features = np.reshape(validation_features, (200, 2 * 2 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map2 = label_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(256, activation='relu', input_dim= 2 * 2 * 512))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                   epochs = 150,\n",
    "                   batch_size = 32,\n",
    "                   validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_class(numeric_id):\n",
    "    for class_pred, id_class in label_map2.items():    # for name, age in dictionary.iteritems():  (for Python 2.x)\n",
    "        if id_class == numeric_id:\n",
    "            return class_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(img_src,img_src_name):\n",
    "    test_features, test_labels, label_map = extract_features(img_src, 1)\n",
    "    test_features = np.reshape(test_features, (1, 2 * 2 * 512))\n",
    "    class_id = return_class(model.predict_classes(test_features)[0])\n",
    "    \n",
    "    img = image.load_img(img_src_name, target_size=(64, 64))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x /= 255.\n",
    "\n",
    "    plt.imshow(x[0])                           \n",
    "    plt.axis('off')\n",
    "    plt.title(class_id)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_prediction('images/unique_test','images/unique_test/class/justin_smile.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:smile] *",
   "language": "python",
   "name": "conda-env-smile-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
