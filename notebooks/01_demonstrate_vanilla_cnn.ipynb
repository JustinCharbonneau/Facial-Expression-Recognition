{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Demonstrate Vanilla CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data as pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the annotations file that contains the label and the image file name\n",
    "labels = pd.read_csv('../data/raw/annotations.csv', header=None, names=['fname','label'])\n",
    "\n",
    "# Shuffle data\n",
    "labels = labels.sample(frac=1).reset_index()\n",
    "\n",
    "# Use a list comprehension to loop over image file names and import one by one and store pixel values\n",
    "x = np.array([image.img_to_array(image.load_img('../data/raw/all/'+fname, target_size=(128, 128))) for fname in labels['fname']])\n",
    "\n",
    "# Because the names are strings, the neural network only takes in numerical formats so we will one-hot encode the label\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels['label'])\n",
    "y = integer_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define an architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (5, 5), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Feed to a densily connected layer for prediction\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizers.Adam(lr=0.001),\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiment for 10 Stratified K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kfold iteration 1/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/5\n",
      "18/18 [==============================] - 8s 458ms/step - loss: 0.7065 - acc: 0.4806 - val_loss: 3.2055 - val_acc: 0.6500\n",
      "Epoch 2/5\n",
      "18/18 [==============================] - 8s 442ms/step - loss: 0.6799 - acc: 0.5444 - val_loss: 5.7778 - val_acc: 0.5500\n",
      "Epoch 3/5\n",
      "18/18 [==============================] - 8s 434ms/step - loss: 0.5841 - acc: 0.6833 - val_loss: 2.0016 - val_acc: 0.8750\n",
      "Epoch 4/5\n",
      "18/18 [==============================] - 8s 435ms/step - loss: 0.4205 - acc: 0.8167 - val_loss: 1.6074 - val_acc: 0.9000\n",
      "Epoch 5/5\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.3347 - acc: 0.8694 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        20\n",
      "           1       1.00      0.60      0.75        20\n",
      "\n",
      "    accuracy                           0.80        40\n",
      "   macro avg       0.86      0.80      0.79        40\n",
      "weighted avg       0.86      0.80      0.79        40\n",
      "\n",
      "Kfold iteration 2/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/5\n",
      "18/18 [==============================] - 8s 455ms/step - loss: 0.6816 - acc: 0.5583 - val_loss: 1.7967 - val_acc: 0.8750\n",
      "Epoch 2/5\n",
      "18/18 [==============================] - 8s 446ms/step - loss: 0.5680 - acc: 0.7028 - val_loss: 1.7936 - val_acc: 0.8750\n",
      "Epoch 3/5\n",
      "18/18 [==============================] - 8s 434ms/step - loss: 0.3362 - acc: 0.8500 - val_loss: 0.3986 - val_acc: 0.9750\n",
      "Epoch 4/5\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.2432 - acc: 0.9028 - val_loss: 0.3986 - val_acc: 0.9750\n",
      "Epoch 5/5\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.2430 - acc: 0.9028 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "Kfold iteration 3/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/5\n",
      "18/18 [==============================] - 8s 455ms/step - loss: 0.7194 - acc: 0.4750 - val_loss: 1.6723 - val_acc: 0.5500\n",
      "Epoch 2/5\n",
      "18/18 [==============================] - 8s 430ms/step - loss: 0.6736 - acc: 0.5889 - val_loss: 1.5157 - val_acc: 0.8500\n",
      "Epoch 3/5\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.4825 - acc: 0.7972 - val_loss: 1.9108 - val_acc: 0.8750\n",
      "Epoch 4/5\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.2230 - acc: 0.9139 - val_loss: 1.2764 - val_acc: 0.9000\n",
      "Epoch 5/5\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.2243 - acc: 0.9139 - val_loss: 2.0060 - val_acc: 0.8750\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        20\n",
      "           1       0.89      0.85      0.87        20\n",
      "\n",
      "    accuracy                           0.88        40\n",
      "   macro avg       0.88      0.88      0.87        40\n",
      "weighted avg       0.88      0.88      0.87        40\n",
      "\n",
      "Kfold iteration 4/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/5\n",
      "18/18 [==============================] - 8s 458ms/step - loss: 0.7147 - acc: 0.4806 - val_loss: 0.1647 - val_acc: 0.9500\n",
      "Epoch 2/5\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.6794 - acc: 0.5528 - val_loss: 0.1549 - val_acc: 0.9750\n",
      "Epoch 3/5\n",
      "18/18 [==============================] - 8s 428ms/step - loss: 0.5546 - acc: 0.7250 - val_loss: 0.8059 - val_acc: 0.9500\n",
      "Epoch 4/5\n",
      "18/18 [==============================] - 8s 434ms/step - loss: 0.3074 - acc: 0.8722 - val_loss: 0.3986 - val_acc: 0.9750\n",
      "Epoch 5/5\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.3176 - acc: 0.8611 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "Kfold iteration 5/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/5\n",
      "18/18 [==============================] - 9s 476ms/step - loss: 0.7036 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/5\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.6936 - acc: 0.5389 - val_loss: 7.3531 - val_acc: 0.5000\n",
      "Epoch 3/5\n",
      "18/18 [==============================] - 8s 424ms/step - loss: 0.6119 - acc: 0.6556 - val_loss: 0.3986 - val_acc: 0.9750\n",
      "Epoch 4/5\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.3462 - acc: 0.8500 - val_loss: 0.3986 - val_acc: 0.9750\n",
      "Epoch 5/5\n",
      "18/18 [==============================] - 8s 426ms/step - loss: 0.2853 - acc: 0.8750 - val_loss: 0.3986 - val_acc: 0.9750\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        20\n",
      "           1       0.95      1.00      0.98        20\n",
      "\n",
      "    accuracy                           0.97        40\n",
      "   macro avg       0.98      0.97      0.97        40\n",
      "weighted avg       0.98      0.97      0.97        40\n",
      "\n",
      "Kfold iteration 6/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/5\n",
      "18/18 [==============================] - 8s 453ms/step - loss: 0.6847 - acc: 0.5611 - val_loss: 1.4926 - val_acc: 0.8250\n",
      "Epoch 2/5\n",
      "18/18 [==============================] - 8s 423ms/step - loss: 0.4814 - acc: 0.7250 - val_loss: 0.8015 - val_acc: 0.9500\n",
      "Epoch 3/5\n",
      "18/18 [==============================] - 8s 429ms/step - loss: 0.2588 - acc: 0.8972 - val_loss: 1.9351 - val_acc: 0.8750\n",
      "Epoch 4/5\n",
      "18/18 [==============================] - 8s 424ms/step - loss: 0.1884 - acc: 0.9250 - val_loss: 1.2001 - val_acc: 0.9250\n",
      "Epoch 5/5\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.2226 - acc: 0.9000 - val_loss: 1.9928 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86        20\n",
      "           1       0.80      1.00      0.89        20\n",
      "\n",
      "    accuracy                           0.88        40\n",
      "   macro avg       0.90      0.88      0.87        40\n",
      "weighted avg       0.90      0.88      0.87        40\n",
      "\n",
      "Kfold iteration 7/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/5\n",
      "18/18 [==============================] - 8s 460ms/step - loss: 0.6938 - acc: 0.4861 - val_loss: 7.2782 - val_acc: 0.5000\n",
      "Epoch 2/5\n",
      "18/18 [==============================] - 9s 518ms/step - loss: 0.5046 - acc: 0.7472 - val_loss: 1.2001 - val_acc: 0.9250\n",
      "Epoch 3/5\n",
      "18/18 [==============================] - 9s 481ms/step - loss: 0.3577 - acc: 0.8639 - val_loss: 0.3986 - val_acc: 0.9750\n",
      "Epoch 4/5\n",
      "18/18 [==============================] - 9s 509ms/step - loss: 0.2517 - acc: 0.9194 - val_loss: 0.8015 - val_acc: 0.9500\n",
      "Epoch 5/5\n",
      "18/18 [==============================] - 11s 596ms/step - loss: 0.2125 - acc: 0.9139 - val_loss: 1.2001 - val_acc: 0.9250\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92        20\n",
      "           1       0.90      0.95      0.93        20\n",
      "\n",
      "    accuracy                           0.93        40\n",
      "   macro avg       0.93      0.93      0.92        40\n",
      "weighted avg       0.93      0.93      0.92        40\n",
      "\n",
      "Kfold iteration 8/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/5\n",
      "18/18 [==============================] - 10s 538ms/step - loss: 0.7036 - acc: 0.4917 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/5\n",
      "18/18 [==============================] - 9s 490ms/step - loss: 0.6662 - acc: 0.6333 - val_loss: 3.4378 - val_acc: 0.7750\n",
      "Epoch 3/5\n",
      "18/18 [==============================] - 12s 640ms/step - loss: 0.4010 - acc: 0.8500 - val_loss: 1.4042 - val_acc: 0.9000\n",
      "Epoch 4/5\n",
      "18/18 [==============================] - 10s 572ms/step - loss: 0.3576 - acc: 0.8694 - val_loss: 0.8015 - val_acc: 0.9500\n",
      "Epoch 5/5\n",
      "18/18 [==============================] - 8s 450ms/step - loss: 0.2719 - acc: 0.8972 - val_loss: 1.1957 - val_acc: 0.9250\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        20\n",
      "           1       0.87      1.00      0.93        20\n",
      "\n",
      "    accuracy                           0.93        40\n",
      "   macro avg       0.93      0.93      0.92        40\n",
      "weighted avg       0.93      0.93      0.92        40\n",
      "\n",
      "Kfold iteration 9/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/5\n",
      "18/18 [==============================] - 8s 456ms/step - loss: 0.6945 - acc: 0.5333 - val_loss: 0.5355 - val_acc: 0.8750\n",
      "Epoch 2/5\n",
      "18/18 [==============================] - 9s 473ms/step - loss: 0.6227 - acc: 0.6972 - val_loss: 0.3986 - val_acc: 0.9750\n",
      "Epoch 3/5\n",
      "18/18 [==============================] - 8s 430ms/step - loss: 0.5054 - acc: 0.7778 - val_loss: 4.5707 - val_acc: 0.7000\n",
      "Epoch 4/5\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.3987 - acc: 0.8361 - val_loss: 0.3986 - val_acc: 0.9750\n",
      "Epoch 5/5\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.3010 - acc: 0.8750 - val_loss: 0.3986 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        20\n",
      "           1       0.95      1.00      0.98        20\n",
      "\n",
      "    accuracy                           0.97        40\n",
      "   macro avg       0.98      0.97      0.97        40\n",
      "weighted avg       0.98      0.97      0.97        40\n",
      "\n",
      "Kfold iteration 10/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/5\n",
      "18/18 [==============================] - 8s 456ms/step - loss: 0.6975 - acc: 0.5056 - val_loss: 0.9124 - val_acc: 0.9000\n",
      "Epoch 2/5\n",
      "18/18 [==============================] - 8s 427ms/step - loss: 0.6018 - acc: 0.6861 - val_loss: 3.5873 - val_acc: 0.7750\n",
      "Epoch 3/5\n",
      "18/18 [==============================] - 8s 427ms/step - loss: 0.4298 - acc: 0.7944 - val_loss: 2.0398 - val_acc: 0.8500\n",
      "Epoch 4/5\n",
      "18/18 [==============================] - 8s 434ms/step - loss: 0.3633 - acc: 0.8500 - val_loss: 1.9928 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/5\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.2447 - acc: 0.8972 - val_loss: 1.1957 - val_acc: 0.9250\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        20\n",
      "           1       0.87      1.00      0.93        20\n",
      "\n",
      "    accuracy                           0.93        40\n",
      "   macro avg       0.93      0.93      0.92        40\n",
      "weighted avg       0.93      0.93      0.92        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All classification reports will be added here. When we are done we can average the f1 scores\n",
    "reports = []\n",
    "\n",
    "# Apply stratified K-fold ith 10 splits. Stratified means the same distribution of classes than the whole dataset\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Just for printing purposes\n",
    "id = 1\n",
    "\n",
    "for train_index, test_index in kf.split(x,y):\n",
    "    print('Kfold iteration {}/10'.format(id))\n",
    "    print('Total images: {} ---- Train images: {} ---- Test images: {}'.format(len(x),len(train_index),len(test_index)))\n",
    "\n",
    "    id += 1 \n",
    "    \n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "    model = build_model()\n",
    "    \n",
    "    datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                 rotation_range=10, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                                 width_shift_range=0.1, # randomly shift images horizontally (fraction of total width)\n",
    "                                 height_shift_range=0.1, \n",
    "                                 shear_range=0.1,\n",
    "                                 zoom_range=0.1)   \n",
    "    \n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # Adjust the learning rate over time. (Like we saw in class!)    \n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "    \n",
    "    history = model.fit_generator(datagen.flow(X_train, y_train, batch_size = 20), epochs = 20, \n",
    "                              validation_data = (X_test,y_test), steps_per_epoch=len(X_train) / 20,\n",
    "                              callbacks=[learning_rate_reduction])\n",
    "\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [np.round(p[0]) for p in y_pred]\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    reports.append(classification_report(y_test, y_pred,output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1-Score is: 92.64%\n"
     ]
    }
   ],
   "source": [
    "# We loop over all reports (1 per fold) and then compute the average of all weighted f1 scores\n",
    "final_f1_score = np.mean([rep['weighted avg']['f1-score'] for rep in reports])\n",
    "\n",
    "print('Final F1-Score is: {}%'.format(np.round(final_f1_score*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:smile] *",
   "language": "python",
   "name": "conda-env-smile-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
